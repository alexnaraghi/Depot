---
phase: 22-streaming-fstat-progress
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src-tauri/src/commands/p4/types.rs
  - src-tauri/src/commands/p4/p4handlers.rs
  - src-tauri/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "Backend command p4_fstat_stream sends batches of files via Tauri Channel"
    - "First batch of files is sent within 500ms of command start"
    - "Process is registered with ProcessManager and can be killed"
    - "Final batch and completion signal are sent when stdout closes"
  artifacts:
    - path: "src-tauri/src/commands/p4/types.rs"
      provides: "FstatStreamBatch enum with Data and Complete variants"
      contains: "FstatStreamBatch"
    - path: "src-tauri/src/commands/p4/p4handlers.rs"
      provides: "p4_fstat_stream streaming command"
      contains: "pub async fn p4_fstat_stream"
    - path: "src-tauri/src/lib.rs"
      provides: "Command registration"
      contains: "p4_fstat_stream"
  key_links:
    - from: "p4handlers.rs:p4_fstat_stream"
      to: "types.rs:FstatStreamBatch"
      via: "Channel<FstatStreamBatch>"
      pattern: "on_batch.*FstatStreamBatch"
    - from: "p4handlers.rs:p4_fstat_stream"
      to: "ProcessManager"
      via: "state.register(child)"
      pattern: "state\\.register\\(child\\)"
---

<objective>
Create streaming backend command for p4 fstat that sends file batches via Tauri Channel.

Purpose: Replace blocking fstat that buffers entire stdout. Enable frontend to receive files incrementally as p4 outputs them, achieving first-batch visibility under 500ms.

Output: `p4_fstat_stream` command that streams batches of 100 files via Channel, with explicit completion signal.
</objective>

<execution_context>
@C:\Users\a\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\a\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-streaming-fstat-progress/22-RESEARCH.md
@src-tauri/src/commands/p4/p4handlers.rs (lines 559-637: p4_sync streaming pattern)
@src-tauri/src/commands/p4/types.rs (P4FileInfo struct)
@src-tauri/src/commands/p4/parsing.rs (build_file_info function)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add FstatStreamBatch type for streaming protocol</name>
  <files>src-tauri/src/commands/p4/types.rs</files>
  <action>
Add a new enum for streaming fstat batches that distinguishes data from completion:

```rust
/// Streaming batch for p4_fstat_stream
/// Data variant contains file batches, Complete signals end of stream
#[derive(Clone, Serialize)]
#[serde(tag = "type", rename_all = "camelCase")]
pub enum FstatStreamBatch {
    Data { files: Vec<P4FileInfo>, total_received: u32 },
    Complete { total_files: u32, success: bool, error: Option<String> },
}
```

The `#[serde(tag = "type")]` creates discriminated union for frontend TypeScript consumption.
Place after P4FileInfo struct definition around line 15.
  </action>
  <verify>Run `cargo check -p p4now` in src-tauri to verify compilation</verify>
  <done>FstatStreamBatch enum exists in types.rs and compiles without errors</done>
</task>

<task type="auto">
  <name>Task 2: Implement p4_fstat_stream command with batched Channel output</name>
  <files>src-tauri/src/commands/p4/p4handlers.rs, src-tauri/src/lib.rs</files>
  <action>
Create `p4_fstat_stream` command following the proven p4_sync pattern (lines 559-637).

Add to p4handlers.rs after p4_fstat (around line 80):

```rust
/// Streaming fstat - sends batches of files via Channel for progressive loading
#[tauri::command]
pub async fn p4_fstat_stream(
    paths: Vec<String>,
    depot_path: Option<String>,
    server: Option<String>,
    user: Option<String>,
    client: Option<String>,
    on_batch: Channel<FstatStreamBatch>,
    state: State<'_, ProcessManager>,
) -> Result<String, String> {
    use std::process::Stdio;
    use tokio::io::{AsyncBufReadExt, BufReader};

    let mut cmd = Command::new("p4");
    apply_connection_args(&mut cmd, &server, &user, &client);

    cmd.arg("-ztag");
    cmd.arg("fstat");

    if paths.is_empty() {
        let query_path = depot_path.unwrap_or_else(|| "//...".to_string());
        cmd.arg(query_path);
    } else {
        cmd.args(&paths);
    }

    cmd.stdout(Stdio::piped());
    cmd.stderr(Stdio::piped());

    let mut child = cmd
        .spawn()
        .map_err(|e| format!("Failed to spawn p4 fstat: {}", e))?;

    let stdout = child.stdout.take();
    let stderr = child.stderr.take();

    // Register process for cancellation
    let process_id = state.register(child).await;
    let process_id_clone = process_id.clone();

    // Stream stdout in background task
    let on_batch_clone = on_batch.clone();
    if let Some(stdout) = stdout {
        tokio::spawn(async move {
            let mut lines = BufReader::new(stdout).lines();
            let mut current_record: HashMap<String, String> = HashMap::new();
            let mut batch: Vec<P4FileInfo> = Vec::new();
            let mut total_received: u32 = 0;

            while let Ok(Some(line)) = lines.next_line().await {
                let line = line.trim();

                // Blank line = end of record
                if line.is_empty() {
                    if !current_record.is_empty() {
                        // Build file info from record, filtering out deleted-at-head files
                        if let Some(file_info) = build_file_info(&current_record) {
                            if file_info.head_action.as_deref() != Some("delete") {
                                batch.push(file_info);

                                // Send batch when it reaches 100 files
                                if batch.len() >= 100 {
                                    total_received += batch.len() as u32;
                                    let _ = on_batch_clone.send(FstatStreamBatch::Data {
                                        files: std::mem::take(&mut batch),
                                        total_received,
                                    });
                                }
                            }
                        }
                        current_record.clear();
                    }
                    continue;
                }

                // Parse ztag line: "... key value"
                if let Some(stripped) = line.strip_prefix("... ") {
                    if let Some((key, value)) = stripped.split_once(' ') {
                        current_record.insert(key.to_string(), value.to_string());
                    } else {
                        // Key with no value (e.g., "... isMapped")
                        current_record.insert(stripped.to_string(), String::new());
                    }
                }
            }

            // Send final batch
            if !batch.is_empty() {
                total_received += batch.len() as u32;
                let _ = on_batch_clone.send(FstatStreamBatch::Data {
                    files: batch,
                    total_received,
                });
            }

            // Send completion signal
            let _ = on_batch_clone.send(FstatStreamBatch::Complete {
                total_files: total_received,
                success: true,
                error: None,
            });
        });
    }

    // Stream stderr in background task (for errors/warnings)
    if let Some(stderr) = stderr {
        let on_batch_stderr = on_batch.clone();
        tokio::spawn(async move {
            let mut lines = BufReader::new(stderr).lines();
            let mut had_error = false;
            let mut error_msg = String::new();

            while let Ok(Some(line)) = lines.next_line().await {
                // Skip informational messages
                if line.contains("no such file(s)") {
                    continue;
                }
                // Log actual errors
                eprintln!("p4 fstat stderr: {}", line);
                if !had_error {
                    had_error = true;
                    error_msg = line;
                }
            }

            // If there were errors and no success completion was sent, send error completion
            if had_error {
                let _ = on_batch_stderr.send(FstatStreamBatch::Complete {
                    total_files: 0,
                    success: false,
                    error: Some(error_msg),
                });
            }
        });
    }

    Ok(process_id_clone)
}
```

Add required imports at top of p4handlers.rs if not present:
- `use std::collections::HashMap;` (already present)
- `use super::types::FstatStreamBatch;`

Register command in src-tauri/src/lib.rs invoke_handler (after p4_fstat):
- Add `commands::p4_fstat_stream,`
  </action>
  <verify>Run `cargo build -p p4now` to verify full compilation</verify>
  <done>p4_fstat_stream command compiles and is registered in invoke_handler</done>
</task>

</tasks>

<verification>
Run the following checks:
1. `cd src-tauri && cargo check` - Verify Rust compiles
2. `cd src-tauri && cargo test` - Verify existing tests still pass
3. Manual inspection: FstatStreamBatch is exported and p4_fstat_stream uses it
</verification>

<success_criteria>
- FstatStreamBatch enum defined with Data and Complete variants
- p4_fstat_stream command exists with Channel<FstatStreamBatch> parameter
- Command registered in lib.rs invoke_handler
- Cargo build succeeds
- Pattern matches proven p4_sync implementation
</success_criteria>

<output>
After completion, create `.planning/phases/22-streaming-fstat-progress/22-01-SUMMARY.md`
</output>
